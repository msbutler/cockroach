new-server name=s1
----

exec-sql
CREATE DATABASE d;
USE d;
CREATE TABLE foo (i INT PRIMARY KEY, s STRING);
CREATE TABLE baz (i INT PRIMARY KEY, s STRING);
INSERT INTO baz VALUES (1, 'x'),(2,'y'),(3,'z');
----

exec-sql
EXPORT INTO CSV 'nodelocal://0/export1/' FROM SELECT * FROM baz WHERE i = 1;
----

exec-sql
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'import.after_ingest';
----

exec-sql
EXPORT INTO CSV 'nodelocal://0/export3/' FROM SELECT * FROM baz WHERE i = 3;
----

# ensure the ImportEpoch increments before planning and does not rollback after the IMPORT INTO
# job gets cancelled
import expect-pausepoint tag=a
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export3/export*-n*.0.csv')
----
job paused at pausepoint

exec-sql
BACKUP TABLE foo INTO 'nodelocal://0/test-root/';
----

query-sql
SELECT
  database_name, object_name, object_type, rows
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/test-root/']
WHERE
  object_name = 'foo';
----
d foo table 2

exec-sql
BACKUP DATABASE d INTO 'nodelocal://0/test-root/';
----

query-sql
SELECT
  database_name, object_name, object_type, rows
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/test-root/']
WHERE
  object_name = 'foo';
----
d foo table 2

# Cancel the job so that the cleanup hook runs.
job cancel=a
----

exec-sql
RESTORE DATABASE d FROM LATEST IN 'nodelocal://0/test-root/' with new_db_name=d2
----

query-sql
SELECT * FROM d2.foo;
----
relation "foo" is offline: importing
