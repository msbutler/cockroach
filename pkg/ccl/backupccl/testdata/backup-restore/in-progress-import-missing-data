# Ensure clear range induces full reintroduction of spans and that restore properly elides
# clear ranged data from initial backup
# - begin import jobs and pause it
# - run inc backup - verify inc has captured the data
# - roll it back it back non-mvcc
# - run an inc backup and ensure we reintroduce the table spans

new-server name=s1 knobs=skip-descriptor-change-intro
----

exec-sql
CREATE DATABASE d;
USE d;
CREATE TABLE foo (i INT PRIMARY KEY, s STRING);
CREATE INDEX foo_idx ON foo (s);
CREATE INDEX foo_to_drop_idx ON foo (s);
CREATE TABLE foofoo (i INT PRIMARY KEY, s STRING);
INSERT INTO foofoo VALUES (10, 'x0');
CREATE TABLE goodfoo (i INT PRIMARY KEY, s STRING);
CREATE TABLE baz (i INT PRIMARY KEY, s STRING);
INSERT INTO baz VALUES (1, 'x'),(2,'y'),(3,'z');
----

exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = 'import.after_ingest';
----

exec-sql
SET CLUSTER SETTING kv.bulkio.write_metadata_sst.enabled = false;
----


exec-sql
EXPORT INTO CSV 'nodelocal://0/export1/' FROM SELECT * FROM baz;
----


# Pause the import job, in order to back up the importing data.
import expect-pausepoint tag=a
IMPORT INTO foo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----
job paused at pausepoint


import expect-pausepoint tag=aa
IMPORT INTO foofoo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----
job paused at pausepoint

import expect-pausepoint tag=aaa
IMPORT INTO goodfoo (i,s) CSV DATA ('nodelocal://0/export1/export*-n*.0.csv')
----
job paused at pausepoint


# Ensure table, database, and cluster full backups capture importing rows.
exec-sql
BACKUP INTO 'nodelocal://0/cluster/' with revision_history;
----


exec-sql
BACKUP DATABASE d INTO 'nodelocal://0/database/' with revision_history;
----

exec-sql
BACKUP TABLE d.* INTO 'nodelocal://0/table/' with revision_history;
----


exec-sql
SET CLUSTER SETTING jobs.debug.pausepoints = '';
----


# Resume the job so the next set of incremental backups observes that tables are back online
job cancel=a
----

job cancel=aa
----

job tag=a wait-for-state=cancelled
----


job tag=aa wait-for-state=cancelled
----

job resume=aaa
----

job tag=aaa wait-for-state=succeeded
----

# Verify proper rollback
query-sql
SELECT count(*) FROM d.foo;
----
0


query-sql
SELECT count(*) FROM d.foofoo;
----
1

# Verify completed import
query-sql
SELECT count(*) FROM d.goodfoo;
----
3


# Even though the full table will get backed up from ts=0 during the next round of incremental
# backups, only active indexes (foo_idx and foo_new_idx) should appear in the restored cluster.
exec-sql
DROP INDEX foo_to_drop_idx;
----
NOTICE: the data for dropped indexes is reclaimed asynchronously
HINT: The reclamation delay can be customized in the zone configuration for the table.

exec-sql
CREATE INDEX foo_new_idx ON foo (s);
----


# Because BackupRestoreTestingKnobs.SkipDescriptorChangeIntroduction is turned on,
# these backup will be unable to introduce foo and foofoo.
exec-sql
BACKUP INTO LATEST IN 'nodelocal://0/cluster/' with revision_history;
----

exec-sql
BACKUP DATABASE d INTO LATEST IN 'nodelocal://0/database/' with revision_history;
----


exec-sql
BACKUP TABLE d.* INTO LATEST IN 'nodelocal://0/table/' with revision_history;
----


# Note that the cluster level SHOW BACKUP includes foo and foofoo in the full
# backup while the the table and database ones do not. This is because CLUSTER
# backup manifests includes these in the Descriptors field (i.e. cluster backups
# explicitly backup offline tables, see #88043), while table and database
# backups only include these descriptors in manifest.DescriptorChanges (see
# #88042).

query-sql
SELECT
  database_name, object_name, object_type, rows, backup_type
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/cluster/']
WHERE
  object_name = 'foo' or object_name = 'foofoo'
ORDER BY
  start_time, database_name;
----
d foo table 3 full
d foofoo table 4 full
d foo table 0 incremental
d foofoo table 1 incremental


# Note that we're purposely skipping the reintroduction of foo and foofoo in the
# incremental to simulate the bug.
query-sql
SELECT
  database_name, object_name, object_type, rows, backup_type
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/database/']
WHERE
  object_name = 'foo' or object_name = 'foofoo'
ORDER BY
  start_time, database_name;
----
d foo table 0 incremental
d foofoo table 0 incremental


query-sql
SELECT
  database_name, object_name, object_type, rows, backup_type
FROM
  [SHOW BACKUP FROM LATEST IN 'nodelocal://0/table/']
WHERE
  object_name = 'foo' or object_name = 'foofoo'
ORDER BY
  start_time, database_name;
----
d foo table 0 incremental
d foofoo table 0 incremental


new-server name=s2 share-io-dir=s1
----


exec-sql
RESTORE DATABASE d FROM LATEST IN 'nodelocal://0/database/';
----
pq: The backup chain did not properly back up table foofoo, which means foofoo is not restorable. To continue the restore, either restore from the different full backup or remove foofoo from the restore targets
HINT: See: https://github.com/cockroachdb/cockroach/issues/88042

# Check that if the corrupt tables are removed, the restore passes
exec-sql
CREATE DATABASE d;
----

exec-sql
RESTORE TABLE d.baz, d.goodfoo FROM LATEST IN 'nodelocal://0/database/';
----


exec-sql
CREATE DATABASE d2;
----

exec-sql
RESTORE TABLE d.* FROM LATEST IN 'nodelocal://0/database/' with into_db=d2;
----
pq: The backup chain did not properly back up table foofoo, which means foofoo is not restorable. To continue the restore, either restore from the different full backup or remove foofoo from the restore targets
HINT: See: https://github.com/cockroachdb/cockroach/issues/88042

exec-sql
RESTORE TABLE d.baz, d.goodfoo FROM LATEST IN 'nodelocal://0/database/' with into_db=d2;
----
